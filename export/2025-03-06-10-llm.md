## Paper:1




1. Title: Wikipedia in the Era of LLMs: Evolution and Risks （大型语言模型时代的维基百科：演变与风险）

2. Authors: Siming Huang, Yuliang Xu, Mingmeng Geng, Yao Wan, Dongping Chen

3. Affiliation: 华中科技大学

4. Keywords: Large Language Models, Wikipedia, Natural Language Processing, machine translation, retrieval-augmented generation

5. Urls: https://arxiv.org/pdf/2503.02879 , Github: https://github.com/HSM316/LLM_Wikipedia

6. Summary: 

- (1): 本文研究背景是大型语言模型（LLMs）的快速发展对维基百科的潜在影响，以及维基百科作为一个重要资源在人工智能领域的广泛应用。
 
- (2): 过去的方法主要分析维基百科的用户指标和AI生成内容的比例，但缺乏对LLMs对维基百科内容及其在自然语言处理任务中影响的全面评估，这使得现有研究不够深入。

- (3): 本文采用网站流量分析和内容评估的方法，通过模拟实验探讨LLMs对维基百科的直接和间接影响，评估其在机器翻译和RAG等相关任务中的作用。

- (4): 研究发现LLMs对维基百科的影响约为1%-2%，并指出如果机器翻译基准受到LLMs影响，模型评分可能膨胀，从而影响比较结果；此外，RAG的有效性可能因LLM生成内容的“污染”而降低。这些结果表明，尽管LLMs尚未完全改变维基百科的语言和知识结构，但未来存在潜在风险，提示需要谨慎对待。
7. Methods: 

- (1): 构建知识库，选取2020年至2024年的Wikinews文章，对每篇文章进行预处理和分段，并通过BERT (Devlin et al., 2019) 进行向量化。

- (2): 使用FAISS库对向量进行索引，以实现高效的相似性搜索和聚类，便于后续的检索过程。

- (3): 将问题进行向量化，并在FAISS中执行相似性搜索，检索出三个最相关的文本段落作为上下文。

- (4): 将检索到的段落与问题结合，构建提示模板，以询问LLMs，答案的选择基于LLM的先前知识和检索到的内容。

- (5): 进行不同的提问方法实验，包括直接询问LLMs、在提示中包含生成问题的Wikinews页面，以及使用RAG在知识库中执行搜索，并分析这几种情况下的表现。

- (6): 对结果进行分析，评估提供外部知识对LLM响应准确率的影响，并通过图形总结不同场景下的准确率数据。





8. Conclusion: 

- (1): 本文的研究意义在于探讨大型语言模型（LLMs）对维基百科的影响，揭示了两者之间的相互关系，并强调了在人工智能及自然语言处理领域中，维基百科内容的重要性和潜在风险。 

- (2): 
  Innovation point: 本文创新性地采用了网站流量分析与模拟实验相结合的方法，全面评估LLMs对维基百科内容和相关任务的影响，填补了现有研究的空白。 
  Performance: 研究结果表明LLMs对维基百科的直接影响约为1%-2%，且可能间接影响机器翻译评分和RAG的有效性，反映出其准确性与潜在风险。 
  Workload: 本文在数据收集和处理方面投入了较大工作量，采用了多样的提问方法和实验设计，以确保结果的完整性和说服力。




